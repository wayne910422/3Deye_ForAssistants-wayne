{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61774e1",
   "metadata": {},
   "source": [
    "隨機抽 Anterior_crop Posterior_crop 20000 變 train-dataset 並且要定位清楚   Anterior Posterior 的照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd882dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import random\n",
    "#import shutil\n",
    "#from pathlib import Path\n",
    "\n",
    "# 設定路徑\n",
    "#anterior_path = Path(\"Anterior_crop\")\n",
    "#posterior_path = Path(\"Posterior_crop\")\n",
    "#train_path = Path(\"cut/train\")\n",
    "\n",
    "# 建立資料夾\n",
    "#(train_path / \"Anterior\").mkdir(parents=True, exist_ok=True)\n",
    "#(train_path / \"Posterior\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 遞迴找圖片檔案\n",
    "#anterior_images_all = list(anterior_path.rglob(\"*.jpg\"))\n",
    "#posterior_images_all = list(posterior_path.rglob(\"*.jpg\"))\n",
    "\n",
    "# 隨機抽樣\n",
    "#anterior_count = min(10000, len(anterior_images_all))\n",
    "#posterior_count = min(10000, len(posterior_images_all))\n",
    "\n",
    "#anterior_images = random.sample(anterior_images_all, anterior_count)\n",
    "#posterior_images = random.sample(posterior_images_all, posterior_count)\n",
    "\n",
    "# 複製圖片\n",
    "#for img in anterior_images:\n",
    "#    shutil.copy(img, train_path / \"Anterior\" / img.name)\n",
    "\n",
    "#for img in posterior_images:\n",
    "#    shutil.copy(img, train_path / \"Posterior\" / img.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e6a38",
   "metadata": {},
   "source": [
    "資料集定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c50cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ image_labels.csv 已成功建立！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# 資料夾路徑\n",
    "anterior_path = Path(r\"C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\")\n",
    "posterior_path = Path(r\"C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Posterior\")\n",
    "\n",
    "# 定義支援的圖片副檔名\n",
    "extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "\n",
    "# 收集所有圖片檔案\n",
    "anterior_images = [f for f in anterior_path.iterdir() if f.suffix.lower() in extensions]\n",
    "posterior_images = [f for f in posterior_path.iterdir() if f.suffix.lower() in extensions]\n",
    "\n",
    "# 寫入 CSV（標註：Anterior=0, Posterior=1）\n",
    "with open(\"image_labels.csv\", \"w\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['filepath', 'label'])  # 欄位名稱\n",
    "\n",
    "    for img in anterior_images:\n",
    "        writer.writerow([str(img), 0])\n",
    "    for img in posterior_images:\n",
    "        writer.writerow([str(img), 1])\n",
    "\n",
    "print(\"✅ image_labels.csv 已成功建立！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ecdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料夾路徑\n",
    "anterior_path = r\"C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\"\n",
    "posterior_path = r\"C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Posterior\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f52b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20230727_013154_frame0000192_right.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20220711_085439_frame0000262_left.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20230920_155516_frame0000367_right.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20231004_200247_frame0001035_right.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20230727_013154_frame0000109_left.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20230815_163628_frame0000477_right.jpg\n",
      "Posterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Posterior\\stream1_20230912_150459_frame0000457_left.jpg\n",
      "Posterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Posterior\\stream1_20220727_174248_frame0000142_left.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20230912_170544_frame0000725_right.jpg\n",
      "Anterior: C:\\Users\\f9104\\Desktop\\cut\\cut\\train\\Anterior\\stream1_20231004_194516_frame0000439_right.jpg\n"
     ]
    }
   ],
   "source": [
    "import random  \n",
    "image_file_paths_with_labels = []\n",
    "\n",
    "for folder in [anterior_path, posterior_path]:\n",
    "    label = os.path.basename(folder)  # 'Anterior' 或 'Posterior'\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            full_path = os.path.join(folder, fname)\n",
    "            image_file_paths_with_labels.append((full_path, label))\n",
    "\n",
    "# 隨機選 10 張圖片\n",
    "random_samples = random.sample(image_file_paths_with_labels, 10)\n",
    "\n",
    "# 印出圖檔與標籤\n",
    "for img_path, label in random_samples:\n",
    "    print(f\"{label}: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7399b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "訓練集數量: 16000, 驗證集數量: 4000\n",
      "\n",
      "Fold 2\n",
      "訓練集數量: 16000, 驗證集數量: 4000\n",
      "\n",
      "Fold 3\n",
      "訓練集數量: 16000, 驗證集數量: 4000\n",
      "\n",
      "Fold 4\n",
      "訓練集數量: 16000, 驗證集數量: 4000\n",
      "\n",
      "Fold 5\n",
      "訓練集數量: 16000, 驗證集數量: 4000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 準備圖像路徑和標籤\n",
    "def load_image_paths_with_labels(base_dirs):\n",
    "    image_paths = []\n",
    "    for base_dir in base_dirs:\n",
    "        label = os.path.basename(base_dir)\n",
    "        for fname in os.listdir(base_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "                image_paths.append((os.path.join(base_dir, fname), label))\n",
    "    return image_paths\n",
    "\n",
    "# 資料夾路徑\n",
    "\n",
    "all_image_data = load_image_paths_with_labels([anterior_path, posterior_path])\n",
    "\n",
    "# 打亂資料\n",
    "random.shuffle(all_image_data)\n",
    "\n",
    "# 分離圖像路徑與標籤\n",
    "image_paths = [x[0] for x in all_image_data]\n",
    "labels = [x[1] for x in all_image_data]\n",
    "\n",
    "# 5 折交叉驗證\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 產生 5 fold 的訓練集與驗證集\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(image_paths)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    train_paths = [image_paths[i] for i in train_index]\n",
    "    val_paths = [image_paths[i] for i in val_index]\n",
    "    train_labels = [labels[i] for i in train_index]\n",
    "    val_labels = [labels[i] for i in val_index]\n",
    "\n",
    "    print(f\"訓練集數量: {len(train_paths)}, 驗證集數量: {len(val_paths)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d6f732",
   "metadata": {},
   "source": [
    "參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e4d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c3b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4e2e3",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867d184",
   "metadata": {},
   "source": [
    "EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247f6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_acc = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, acc):\n",
    "        if acc > self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bd83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = 0 if self.labels[idx] == 'Anterior' else 1\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc3c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNN is enabled: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    cudnn.benchmark = True    # 對固定輸入尺寸有加速效果\n",
    "    cudnn.enabled = True      # 開啟 cuDNN 支援（預設為 True）\n",
    "    print(\"cuDNN is enabled:\", cudnn.enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d962d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_model():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)  # 二分類\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adb1ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dirs = []\n",
    "for fold in range(5):\n",
    "    fold_dir = f\"./fold_{fold + 1}\"\n",
    "    model_dir = os.path.join(fold_dir, \"models\")\n",
    "    csv_path = os.path.join(fold_dir, \"metrics.csv\")\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    output_dirs.append({\n",
    "        \"fold_dir\": fold_dir,\n",
    "        \"model_dir\": model_dir,\n",
    "        \"csv_path\": csv_path\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6becdca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 20000 items.\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageDataset(image_paths, labels, transform=None)\n",
    "\n",
    "# 檢查是否有資料\n",
    "if len(dataset) == 0:\n",
    "    print(\"Dataset is empty.\")\n",
    "else:\n",
    "    print(f\"Dataset contains {len(dataset)} items.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前使用設備： cuda\n",
      "GPU 名稱： NVIDIA GeForce RTX 4080 SUPER\n",
      "cuDNN 是否啟用： True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"目前使用設備：\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU 名稱：\", torch.cuda.get_device_name(0))\n",
    "    print(\"cuDNN 是否啟用：\", torch.backends.cudnn.enabled)\n",
    "else:\n",
    "    print(\" 沒有偵測到可用的 GPU，將使用 CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98719757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f9104\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\f9104\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Fold 1 | Epoch 1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 用來儲存每個 fold 的最佳結果\n",
    "fold_summaries = []\n",
    "\n",
    "# 進行 5-fold Cross Validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(image_paths)):\n",
    "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "\n",
    "    # 切分資料：train / val+test\n",
    "    train_paths = [image_paths[i] for i in train_index]\n",
    "    train_labels = [labels[i] for i in train_index]\n",
    "\n",
    "    val_paths_full = [image_paths[i] for i in val_index]\n",
    "    val_labels_full = [labels[i] for i in val_index]\n",
    "\n",
    "    split_idx = len(val_paths_full) // 2\n",
    "    val_paths = val_paths_full[:split_idx]\n",
    "    val_labels = val_labels_full[:split_idx]\n",
    "    test_paths = val_paths_full[split_idx:]\n",
    "    test_labels = val_labels_full[split_idx:]\n",
    "\n",
    "    # 建立 Dataset 和 DataLoader\n",
    "    train_dataset = ImageDataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_paths, val_labels, transform=val_transform)\n",
    "    test_dataset = ImageDataset(test_paths, test_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=10)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=10)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=10)\n",
    "\n",
    "    # 初始化模型與訓練參數\n",
    "    model = get_model()\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)  # 二分類\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    # 訓練過程\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Fold {fold+1} | Epoch {epoch+1} [Train]\", leave=False)\n",
    "        for images, targets in loop:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(val_loader, desc=f\"Fold {fold+1} | Epoch {epoch+1} [Val]\", leave=False):\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == targets).sum().item()\n",
    "                val_total += targets.size(0)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\")\n",
    "\n",
    "        metrics.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc\n",
    "        })\n",
    "\n",
    "        if val_acc >= early_stopping.best_acc:\n",
    "            model_save_path = os.path.join(output_dirs[fold][\"model_dir\"], \"best_model.pth\")\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "        early_stopping(val_acc)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # 儲存訓練過程紀錄\n",
    "    df_metrics = pd.DataFrame(metrics)\n",
    "    df_metrics.to_csv(output_dirs[fold][\"csv_path\"], index=False)\n",
    "\n",
    "    # 混淆矩陣圖\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Anterior', 'Posterior'])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f\"Fold {fold+1} Confusion Matrix\")\n",
    "    plt.savefig(os.path.join(output_dirs[fold][\"fold_dir\"], f\"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Accuracy 折線圖\n",
    "    plt.figure()\n",
    "    plt.plot(df_metrics['epoch'], df_metrics['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(df_metrics['epoch'], df_metrics['val_acc'], label='Val Accuracy')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Fold {fold+1} Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dirs[fold][\"fold_dir\"], f\"accuracy_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Loss 折線圖\n",
    "    plt.figure()\n",
    "    plt.plot(df_metrics['epoch'], df_metrics['train_loss'], label='Train Loss')\n",
    "    plt.plot(df_metrics['epoch'], df_metrics['val_loss'], label='Val Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Fold {fold+1} Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dirs[fold][\"fold_dir\"], f\"loss_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # 測試集準確率計算\n",
    "    test_correct, test_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            test_correct += (preds == targets).sum().item()\n",
    "            test_total += targets.size(0)\n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\" Fold {fold+1} Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # 收集最佳結果\n",
    "    best_row = df_metrics.loc[df_metrics['val_acc'].idxmax()]\n",
    "    fold_summaries.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_epoch': int(best_row['epoch']),\n",
    "        'train_acc': best_row['train_acc'],\n",
    "        'val_acc': best_row['val_acc'],\n",
    "        'train_loss': best_row['train_loss'],\n",
    "        'val_loss': best_row['val_loss'],\n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "\n",
    "# 輸出 summary.csv\n",
    "df_summary = pd.DataFrame(fold_summaries)\n",
    "mean_row = {\n",
    "    'fold': 'Average',\n",
    "    'best_epoch': '-',\n",
    "    'train_acc': df_summary['train_acc'].mean(),\n",
    "    'val_acc': df_summary['val_acc'].mean(),\n",
    "    'train_loss': df_summary['train_loss'].mean(),\n",
    "    'val_loss': df_summary['val_loss'].mean(),\n",
    "    'test_acc': df_summary['test_acc'].mean()\n",
    "}\n",
    "df_summary = pd.concat([df_summary, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "df_summary.to_csv(\"summary.csv\", index=False)\n",
    "print(\"\\n summary.csv saved. Here is the summary:\")\n",
    "print(df_summary)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
